# Sample environment variables for data processing scripts
# Copy this file to .env in the data_processing directory and fill in your actual values.
# DO NOT COMMIT THE ACTUAL .env FILE if it contains secrets.

# --- Logging ---
# Controls the verbosity of script output (e.g., DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# --- Google Cloud Storage ---
# Name of the GCS bucket where the MovieLens zip file will be stored/retrieved.
GCS_BUCKET_NAME=your-movielens-data-bucket

# Optional: Specify a sub-path within the bucket for datasets
# GCS_DATASET_PATH="datasets/" # Results in gs://<bucket>/datasets/file.zip

# --- MongoDB ---
# Connection URI for your MongoDB instance (e.g., Atlas M0 cluster).
# Ensure your machine's IP is whitelisted in Atlas if required.
MONGODB_URI="mongodb://user:password@your_mongodb_host:port/your_database_name?retryWrites=true&w=majority"
# Example for local MongoDB:
# MONGODB_URI="mongodb://localhost:27017/movielens_db"

# --- MovieLens Source ---
# URL to download the dataset zip file from.
MOVIELENS_URL="https://files.grouplens.org/datasets/movielens/ml-latest-small.zip"

# The expected filename of the dataset within GCS (used by scripts to locate the file).
MOVIELENS_ZIP_FILENAME="ml-latest-small.zip"

# --- Embeddings ---
# Hugging Face Sentence Transformer model name to use for generating embeddings.
HF_MODEL_NAME="sentence-transformers/all-MiniLM-L6-v2"

# Optional: Specify the device for embedding generation ('cuda' for GPU, 'cpu', or leave empty for auto-detection).
# HF_DEVICE=cuda

# Optional: Batch size for processing embeddings (adjust based on memory).
# EMBEDDING_BATCH_SIZE=64

# --- Optional: Redis (if update_recommendations.py uses it) ---
# Connection URL for your Redis instance.
# REDIS_URL="redis://:password@your_redis_host:port/0"
# Example for local Redis:
# REDIS_URL="redis://localhost:6379/0"